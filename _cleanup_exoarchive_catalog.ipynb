{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build and cleanup catalog from exoplanet archive PSComp\n",
    "\n",
    "#### Performs the following steps: \n",
    "1. Removes controversial planets, circumbinaries, and objects not in transiting/RV systems\n",
    "2. Crossmatches the Gaia-Kepler sample (Berger+ 2020)\n",
    "3. Enforces stellar parameter consistency in each system\n",
    "4. Recomputues $r_p/R_{\\star}$ and $N_{\\rm pl}$ for each system\n",
    "5. Eliminates low-multiplicity and transiting systems with unreliable data\n",
    "6. Flags remaining high-priority targets with missing data in need of follow-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from scipy.optimize import newton\n",
    "\n",
    "from oviraptor.utils import *\n",
    "from oviraptor.constants import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAINPATH = 'C:/Users/djhoo/Documents/Oviraptor-master/'\n",
    "MAINPATH = \"/Users/research/projects/oviraptor/\"\n",
    "\n",
    "pscomposite_file = MAINPATH + \"Catalogs/exoarchive_pscomposite_20210531.csv\"\n",
    "ps_rv_multi_file = MAINPATH + \"Catalogs/exoarchive_ps_rv_multis_20210531.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in ExoArchive data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of queried objects = 4389\n"
     ]
    }
   ],
   "source": [
    "# here's the data\n",
    "keys, vals = read_csv_file(pscomposite_file, k_index=99, v_index=100)\n",
    "\n",
    "data = {}\n",
    "for k in keys:\n",
    "    data[k] = np.array(get_csv_data(k, keys, vals))\n",
    "    \n",
    "\n",
    "# grab a reference key\n",
    "k0 = list(data.keys())[0]\n",
    "\n",
    "print('total number of queried objects =', len(data[k0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pl_name\n",
      "hostname\n",
      "gaia_id\n",
      "sy_snum\n",
      "sy_pnum\n",
      "cb_flag\n",
      "discoverymethod\n",
      "disc_year\n",
      "disc_refname\n",
      "disc_facility\n",
      "disc_telescope\n",
      "disc_instrument\n",
      "pl_controv_flag\n",
      "pl_orbper\n",
      "pl_orbpererr1\n",
      "pl_orbpererr2\n",
      "pl_orbperlim\n",
      "pl_rade\n",
      "pl_radeerr1\n",
      "pl_radeerr2\n",
      "pl_radelim\n",
      "pl_radj\n",
      "pl_radjerr1\n",
      "pl_radjerr2\n",
      "pl_radjlim\n",
      "pl_bmasse\n",
      "pl_bmasseerr1\n",
      "pl_bmasseerr2\n",
      "pl_bmasselim\n",
      "pl_bmassj\n",
      "pl_bmassjerr1\n",
      "pl_bmassjerr2\n",
      "pl_bmassjlim\n",
      "pl_bmassprov\n",
      "pl_orbeccen\n",
      "pl_orbeccenerr1\n",
      "pl_orbeccenerr2\n",
      "pl_orbeccenlim\n",
      "ttv_flag\n",
      "pl_ratror\n",
      "pl_ratrorerr1\n",
      "pl_ratrorerr2\n",
      "pl_ratrorlim\n",
      "pl_rvamp\n",
      "pl_rvamperr1\n",
      "pl_rvamperr2\n",
      "pl_rvamplim\n",
      "st_spectype\n",
      "st_teff\n",
      "st_tefferr1\n",
      "st_tefferr2\n",
      "st_tefflim\n",
      "st_rad\n",
      "st_raderr1\n",
      "st_raderr2\n",
      "st_radlim\n",
      "st_mass\n",
      "st_masserr1\n",
      "st_masserr2\n",
      "st_masslim\n",
      "st_met\n",
      "st_meterr1\n",
      "st_meterr2\n",
      "st_metlim\n",
      "st_metratio\n",
      "st_logg\n",
      "st_loggerr1\n",
      "st_loggerr2\n",
      "st_logglim\n",
      "rastr\n",
      "ra\n",
      "decstr\n",
      "dec\n",
      "sy_dist\n",
      "sy_disterr1\n",
      "sy_disterr2\n",
      "sy_plx\n",
      "sy_plxerr1\n",
      "sy_plxerr2\n",
      "sy_vmag\n",
      "sy_vmagerr1\n",
      "sy_vmagerr2\n",
      "sy_kmag\n",
      "sy_kmagerr1\n",
      "sy_kmagerr2\n",
      "sy_gaiamag\n",
      "sy_gaiamagerr1\n",
      "sy_gaiamagerr2\n",
      "sy_kepmag\n",
      "sy_kepmagerr1\n",
      "sy_kepmagerr2\n",
      "st_nphot\n",
      "st_nrvc\n"
     ]
    }
   ],
   "source": [
    "for k in data.keys():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove unwanted objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed 193 objects due to non-relevant DETECTION METHOD\n",
      "removed 14 objects flagged as CONTROVERSIAL\n",
      "removed 14 objects in CIRCUMBINARY systems\n",
      "\n",
      "after cuts, 4168 objects remain in 3073 systems \n",
      "\n",
      "3314 TRANSITING planets\n",
      "833 RADIAL VELOCITY planets\n",
      "21 TTV planets\n"
     ]
    }
   ],
   "source": [
    "# filter detection methods\n",
    "keep = (data[\"discoverymethod\"] == \"Transit\") + \\\n",
    "       (data[\"discoverymethod\"] == \"Radial Velocity\") + \\\n",
    "       (data[\"discoverymethod\"] == \"Transit Timing Variations\")\n",
    "\n",
    "for k in data.keys():\n",
    "    data[k] = data[k][keep]\n",
    "\n",
    "print(\"removed {0} objects due to non-relevant DETECTION METHOD\".format(np.sum(~keep)))\n",
    "\n",
    "\n",
    "# controversial flag\n",
    "bad = data[\"pl_controv_flag\"] == \"1\"\n",
    "\n",
    "for k in data.keys():\n",
    "    data[k] = data[k][~bad]\n",
    "\n",
    "print(\"removed {0} objects flagged as CONTROVERSIAL\".format(np.sum(bad)))\n",
    "\n",
    "\n",
    "# circumbinary planets\n",
    "bad = data[\"cb_flag\"] == \"1\"\n",
    "\n",
    "for k in data.keys():\n",
    "    data[k] = data[k][~bad]\n",
    "\n",
    "print(\"removed {0} objects in CIRCUMBINARY systems\".format(np.sum(bad)))\n",
    "\n",
    "\n",
    "print(\"\\nafter cuts, {0} objects remain in {1} systems \\n\".format(len(data[k0]), len(np.unique(data[\"hostname\"]))))\n",
    "\n",
    "print(\"{0} TRANSITING planets\".format(np.sum(data[\"discoverymethod\"] == \"Transit\")))\n",
    "print(\"{0} RADIAL VELOCITY planets\".format(np.sum(data[\"discoverymethod\"] == \"Radial Velocity\")))\n",
    "print(\"{0} TTV planets\".format(np.sum(data[\"discoverymethod\"] == \"Transit Timing Variations\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fix planet count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, starname in enumerate(np.unique(data[\"hostname\"])):\n",
    "    use = data[\"hostname\"] == starname\n",
    "    \n",
    "    data[\"sy_pnum\"][use] = np.sum(use)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in Kepler names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "kepnamepath = MAINPATH + \"Catalogs/kepler_names.txt\"\n",
    "\n",
    "# read in the stellar output parameters\n",
    "with open(kepnamepath, \"r\") as infile:\n",
    "    raw_kepnames = []\n",
    "    \n",
    "    for i, line in enumerate(infile):\n",
    "        raw_kepnames.append(line.split(\",\"))\n",
    "            \n",
    "raw_kepnames = np.array(raw_kepnames)\n",
    "\n",
    "# strip off trailing \\newline commands\n",
    "for i in range(len(raw_kepnames)):\n",
    "    raw_kepnames[i,-1] = raw_kepnames[i,-1].strip(\"\\n\").strip(\"\\ \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "kepnames = {}\n",
    "\n",
    "for i, k in enumerate(raw_kepnames[0]):\n",
    "    kepnames[k] = raw_kepnames[1:,i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in Gaia DR2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaiapath = MAINPATH + \"Catalogs/berger_2020_gaia_kepler_tab2_output.txt\"\n",
    "\n",
    "# read in the stellar output parameters\n",
    "with open(gaiapath, \"r\") as infile:\n",
    "    raw_gaia_data = []\n",
    "    \n",
    "    for i, line in enumerate(infile):\n",
    "        raw_gaia_data.append(line.split(\"&\"))\n",
    "            \n",
    "raw_gaia_data = np.array(raw_gaia_data)\n",
    "\n",
    "\n",
    "# strip off trailing \\newline commands\n",
    "for i in range(len(raw_gaia_data)):\n",
    "    raw_gaia_data[i,-1] = raw_gaia_data[i,-1].strip(\"\\n\").strip(\"\\ \")\n",
    "    \n",
    "    \n",
    "gaia_stars = {}\n",
    "\n",
    "for i, k in enumerate(raw_gaia_data[0]):\n",
    "    gaia_stars[k] = raw_gaia_data[1:,i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaiapath = MAINPATH + \"Catalogs/berger_2020_gaia_kepler_planets.txt\"\n",
    "\n",
    "gaia_planets = {}\n",
    "\n",
    "gaia_planets[\"KIC\"] = np.loadtxt(gaiapath, skiprows=32, dtype=\"str\", usecols=0)\n",
    "gaia_planets[\"radius\"] = np.loadtxt(gaiapath, skiprows=32, dtype=\"str\", usecols=3)\n",
    "gaia_planets[\"radius_err1\"] = np.loadtxt(gaiapath, skiprows=32, dtype=\"str\", usecols=4)\n",
    "gaia_planets[\"radius_err2\"] = np.loadtxt(gaiapath, skiprows=32, dtype=\"str\", usecols=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-match Kepler vs. Gaia and combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# populate empty stellar reference column\n",
    "data[\"st_refname\"] = np.array([\"\"]*len(data[k0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaia_kic = np.asarray(gaia_stars[\"KIC\"], dtype=\"int\")\n",
    "\n",
    "for i in range(len(data[k0])):\n",
    "    hostname = data[\"hostname\"][i]\n",
    "    \n",
    "    if hostname[:3] == \"Kep\":\n",
    "        \n",
    "        for j, kname in enumerate(kepnames[\"kepler_name\"]):\n",
    "            if kname[:-2] == hostname:\n",
    "                kic = int(kepnames[\"kepid\"][j])\n",
    "        \n",
    "        match = gaia_kic == kic\n",
    "        \n",
    "        if np.sum(match) == 1:\n",
    "            data[\"st_refname\"][i] = \"Berger et al. 2020\"\n",
    "            \n",
    "            data[\"st_teff\"][i] = gaia_stars[\"iso_teff\"][match][0]\n",
    "            data[\"st_tefferr1\"][i] = gaia_stars[\"iso_teff_err1\"][match][0]\n",
    "            data[\"st_tefferr1\"][i] = gaia_stars[\"iso_teff_err2\"][match][0]\n",
    "            data[\"st_tefflim\"][i]  = \"0\"\n",
    "            \n",
    "            data[\"st_rad\"][i] = gaia_stars[\"iso_rad\"][match][0]\n",
    "            data[\"st_raderr1\"][i] = gaia_stars[\"iso_rad_err1\"][match][0]\n",
    "            data[\"st_raderr1\"][i] = gaia_stars[\"iso_rad_err2\"][match][0]\n",
    "            data[\"st_radlim\"][i]  = \"0\"\n",
    "            \n",
    "            data[\"st_mass\"][i] = gaia_stars[\"iso_mass\"][match][0]\n",
    "            data[\"st_masserr1\"][i] = gaia_stars[\"iso_mass_err1\"][match][0]\n",
    "            data[\"st_masserr1\"][i] = gaia_stars[\"iso_mass_err2\"][match][0]\n",
    "            data[\"st_masslim\"][i]  = \"0\"\n",
    "            \n",
    "            data[\"st_met\"][i] = gaia_stars[\"iso_feh\"][match][0]\n",
    "            data[\"st_meterr1\"][i] = gaia_stars[\"iso_feh_err1\"][match][0]\n",
    "            data[\"st_meterr1\"][i] = gaia_stars[\"iso_feh_err2\"][match][0]\n",
    "            data[\"st_metlim\"][i]  = \"0\"\n",
    "            data[\"st_metratio\"][i]  = \"[Fe/H]\"\n",
    "            \n",
    "            data[\"st_logg\"][i] = gaia_stars[\"iso_logg\"][match][0]\n",
    "            data[\"st_loggerr1\"][i] = gaia_stars[\"iso_logg_err1\"][match][0]\n",
    "            data[\"st_loggerr1\"][i] = gaia_stars[\"iso_logg_err2\"][match][0]\n",
    "            data[\"st_logglim\"][i]  = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaia_kic = np.asarray(gaia_planets[\"KIC\"], dtype=\"int\")\n",
    "\n",
    "count = 0\n",
    "\n",
    "for i in range(len(data[k0])):\n",
    "    hostname = data[\"hostname\"][i]\n",
    "    \n",
    "    if hostname[:3] == \"Kep\":\n",
    "        \n",
    "        for j, kname in enumerate(kepnames[\"kepler_name\"]):\n",
    "            if kname[:-2] == hostname:\n",
    "                kic = int(kepnames[\"kepid\"][j])\n",
    "        \n",
    "        match = gaia_kic == kic\n",
    "        \n",
    "        if np.sum(match) == 1:\n",
    "            data[\"pl_rade\"][i] = gaia_planets[\"radius\"][match][0]\n",
    "            data[\"pl_radeerr1\"][i] = gaia_planets[\"radius_err1\"][match][0]\n",
    "            data[\"pl_radeerr1\"][i] = gaia_planets[\"radius_err2\"][match][0]\n",
    "            data[\"pl_radelim\"][i]  = \"0\"\n",
    "            \n",
    "            RERJ = REARTH/RJUP\n",
    "            \n",
    "            data[\"pl_radj\"][i] = str(np.round(float(gaia_planets[\"radius\"][match][0])*RERJ,3))\n",
    "            data[\"pl_radjerr1\"][i] = str(np.round(float(gaia_planets[\"radius_err1\"][match][0])*RERJ,3))\n",
    "            data[\"pl_radjerr1\"][i] = str(np.round(float(gaia_planets[\"radius_err2\"][match][0])*RERJ,3))\n",
    "            data[\"pl_radjlim\"][i]  = \"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enforce stellar parameter consistency for each system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, star in enumerate(np.unique(data[\"hostname\"])):\n",
    "    use = data[\"hostname\"] == star\n",
    "    npl = int(data[\"sy_pnum\"][use][0])\n",
    "    \n",
    "    for k in data.keys():\n",
    "        if (k[:2] == \"st\")*(npl > 1):\n",
    "            if np.any(data[k][use] != data[k][use][0]):\n",
    "                \n",
    "                # grab relevant values\n",
    "                vals = data[k][use]\n",
    "                \n",
    "                # overwrite missing values\n",
    "                if npl == 2:\n",
    "                    if np.any(vals == \"\"):\n",
    "                        data[k][use] = vals[vals != \"\"]\n",
    "                \n",
    "                \n",
    "                # for high-multiplicity systems, use the most common value\n",
    "                if npl > 2:\n",
    "                    count = np.array([list(vals).count(v) for v in vals])\n",
    "                    count[vals == \"\"] = 0\n",
    "                    \n",
    "                    if np.any(count > 0) * ~np.all(count == 1):\n",
    "                        data[k][use] = data[k][use][np.argmax(count)]\n",
    "                    \n",
    "                \n",
    "                \n",
    "                # now enforce consistency by taking mean\n",
    "                vals[vals == \"\"] = \"nan\"\n",
    "                \n",
    "                try:\n",
    "                    data[k][use] = np.nanmean(np.asarray(vals, dtype=\"float\"))\n",
    "                except:\n",
    "                    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for missing stellar data (should be very few systems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Missing MASS\n",
      "[]\n",
      "\n",
      "\n",
      "Missing RADIUS\n",
      "['GJ 667 C']\n",
      "\n",
      "\n",
      "Missing TEMPERATURE\n",
      "['SWEEPS-11' 'SWEEPS-4']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\nMissing MASS\")\n",
    "print(np.unique(data[\"hostname\"][data[\"st_mass\"] == \"\"]))\n",
    "\n",
    "print(\"\\n\\nMissing RADIUS\")\n",
    "print(np.unique(data[\"hostname\"][data[\"st_rad\"] == \"\"]))\n",
    "\n",
    "print(\"\\n\\nMissing TEMPERATURE\")\n",
    "print(np.unique(data[\"hostname\"][data[\"st_teff\"] == \"\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 3 systems missing stellar mass, radius, or temperature\n"
     ]
    }
   ],
   "source": [
    "bad = (data[\"st_mass\"] == \"\") + (data[\"st_rad\"] == \"\") + (data[\"st_teff\"] == \"\")\n",
    "nsys = len(np.unique(data[\"hostname\"][bad]))\n",
    "\n",
    "for k in data.keys():\n",
    "    data[k] = data[k][~bad]\n",
    "    \n",
    "\n",
    "print(\"Removed {0} systems missing stellar mass, radius, or temperature\".format(nsys))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Track non-*Kepler* stars in TICv8 compatible format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a list of non-Kepler stars to upload to MAST in order to query TICv8\n",
    "# https://mast.stsci.edu/portal/Mashup/Clients/Mast/Portal.html\n",
    "\n",
    "use = data[\"disc_facility\"] != \"Kepler\"\n",
    "\n",
    "nonkep_fmt = [\"#@string\", \"ra\", \"dec\"]\n",
    "nonkep_header = [\"TARGET\", \"RA\", \"DEC\"]\n",
    "nonkep_data = np.vstack([np.unique(data[\"hostname\"][use]),\n",
    "                         np.unique(data[\"ra\"][use]),\n",
    "                         np.unique(data[\"dec\"][use])]).swapaxes(0,1)\n",
    "\n",
    "nonkep_targets = np.vstack([nonkep_fmt, nonkep_header, nonkep_data])\n",
    "\n",
    "np.savetxt(\"Catalogs/non_kepler_stars.csv\", nonkep_targets, fmt=(\"%s\", \"%s\", \"%s\"), delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label each system as \"Transit\", \"Radial Velocity\", or \"Mixed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"system_type\"] = np.array([\"\"]*len(data[k0]), dtype=\"<U29\")\n",
    "\n",
    "\n",
    "for i, star in enumerate(data[\"hostname\"]):\n",
    "    use = data[\"hostname\"] == star\n",
    "    \n",
    "    if np.all(data[\"discoverymethod\"][use] == \"Transit\"):\n",
    "        data[\"system_type\"][use] = \"Transit\"\n",
    "        \n",
    "    elif np.all(data[\"discoverymethod\"][use] == \"Radial Velocity\"):\n",
    "        data[\"system_type\"][use] = \"Radial Velocity\"\n",
    "        \n",
    "    else:\n",
    "        data[\"system_type\"][use] = \"Mixed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for transiting planets missing $r_p/R_{\\star}$ and calculate manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad = np.zeros(len(data[\"discoverymethod\"]), dtype=\"bool\")\n",
    "\n",
    "check_keys = [\"pl_ratror\", \"pl_ratrorerr1\", \"pl_ratrorerr2\"]\n",
    "\n",
    "for k in check_keys:\n",
    "    bad += data[k] == \"\"\n",
    "    bad += data[k] == \"nan\"\n",
    "    \n",
    "bad *= (data[\"discoverymethod\"] == \"Transit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "rad_keys = [\"pl_rade\", \"pl_radeerr1\", \"pl_radeerr2\", \"st_rad\", \"st_raderr1\", \"st_raderr2\"]\n",
    "rad_data = {}\n",
    "\n",
    "for i, k in enumerate(rad_keys):\n",
    "    rad_data[k] = data[k][bad]\n",
    "    rad_data[k][rad_data[k] == \"\"] = \"nan\"\n",
    "    rad_data[k] = np.asarray(rad_data[k], dtype=\"float\")\n",
    "    \n",
    "    \n",
    "data[\"pl_ratror\"][bad] = rad_data[\"pl_rade\"]/rad_data[\"st_rad\"]*REARTH/RSUN\n",
    "data[\"pl_ratrorerr1\"][bad] = rad_data[\"pl_radeerr1\"]/rad_data[\"st_rad\"]*REARTH/RSUN\n",
    "data[\"pl_ratrorerr2\"][bad] = rad_data[\"pl_radeerr2\"]/rad_data[\"st_rad\"]*REARTH/RSUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed the following transiting planets due to missing radius ratio information:\n",
      "['HD 3167 d' 'HD 72490 b' 'KOI-142 c' 'Kepler-430 b' 'Kepler-430 c'\n",
      " 'Kepler-431 b' 'Kepler-431 c' 'Kepler-431 d']\n"
     ]
    }
   ],
   "source": [
    "# Remove any transiting planets still missing rp/Rs\n",
    "bad = np.zeros(len(data[\"discoverymethod\"]), dtype=\"bool\")\n",
    "\n",
    "check_keys = [\"pl_ratror\", \"pl_ratrorerr1\", \"pl_ratrorerr2\"]\n",
    "\n",
    "for k in check_keys:\n",
    "    bad += data[k] == \"\"\n",
    "    bad += data[k] == \"nan\"\n",
    "    \n",
    "bad *= (data[\"discoverymethod\"] == \"Transit\")\n",
    "\n",
    "print(\"Removed the following transiting planets due to missing radius ratio information:\")\n",
    "print(data[\"pl_name\"][bad])\n",
    "\n",
    "for k in data.keys():\n",
    "    data[k] = data[k][~bad]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for RV planets missing RV semi-amplitude and calculate manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad = np.zeros(len(data[\"discoverymethod\"]), dtype=\"bool\")\n",
    "\n",
    "check_keys = [\"pl_rvamp\", \"pl_rvamperr1\", \"pl_rvamperr2\"]\n",
    "\n",
    "for k in check_keys:\n",
    "    bad += data[k] == \"\"\n",
    "    bad += data[k] == \"nan\"\n",
    "    \n",
    "bad *= (data[\"discoverymethod\"] == \"Radial Velocity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mass_keys = [\"pl_bmasse\", \"pl_bmasseerr1\", \"pl_bmasseerr2\", \"st_mass\", \"st_masserr1\", \"st_masserr2\"]\n",
    "mass_data = {}\n",
    "\n",
    "for i, k in enumerate(mass_keys):\n",
    "    mass_data[k] = data[k][bad]\n",
    "    mass_data[k][mass_data[k] == \"\"] = \"nan\"\n",
    "    mass_data[k] = np.asarray(mass_data[k], dtype=\"float\")\n",
    "    \n",
    "    \n",
    "data[\"pl_rvamp\"][bad] = mass_data[\"pl_bmasse\"]/mass_data[\"st_mass\"]*MEARTH/MSUN\n",
    "data[\"pl_rvamperr1\"][bad] = mass_data[\"pl_bmasseerr1\"]/mass_data[\"st_mass\"]*MEARTH/MSUN\n",
    "data[\"pl_rvamperr2\"][bad] = mass_data[\"pl_bmasseerr2\"]/mass_data[\"st_mass\"]*MEARTH/MSUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed the following RV planets due to missing RV semi-amplitude information:\n",
      "['91 Aqr b' 'HIP 63242 b' 'Kepler-93 c' 'Kepler-97 c' 'bet Pic c'\n",
      " 'tau Gem b']\n"
     ]
    }
   ],
   "source": [
    "# Remove any radial velocity planets still missing RV semi-amplitude\n",
    "bad = np.zeros(len(data[\"discoverymethod\"]), dtype=\"bool\")\n",
    "\n",
    "check_keys = [\"pl_rvamp\", \"pl_rvamperr1\", \"pl_rvamperr2\"]\n",
    "\n",
    "for k in check_keys:\n",
    "    bad += data[k] == \"\"\n",
    "    bad += data[k] == \"nan\"\n",
    "    \n",
    "bad *= (data[\"discoverymethod\"] == \"Radial Velocity\")\n",
    "\n",
    "print(\"Removed the following RV planets due to missing RV semi-amplitude information:\")\n",
    "print(data[\"pl_name\"][bad])\n",
    "\n",
    "for k in data.keys():\n",
    "    data[k] = data[k][~bad]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check that TTV planets have either a mass or radius with uncertainties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed the following TTV planets missing both mass and radius informatino:\n",
      "['Kepler-160 d']\n"
     ]
    }
   ],
   "source": [
    "no_mass = np.zeros(len(data[\"discoverymethod\"]), dtype=\"bool\")\n",
    "mkeys = [\"pl_bmasse\", \"pl_bmasseerr1\", \"pl_bmasseerr2\"]\n",
    "for k in mkeys:\n",
    "    no_mass += data[k] == \"\"\n",
    "    no_mass += data[k] == \"nan\"\n",
    "    \n",
    "    \n",
    "no_rad = np.zeros(len(data[\"discoverymethod\"]), dtype=\"bool\")\n",
    "rkeys = [\"pl_rade\", \"pl_radeerr1\", \"pl_radeerr2\"]\n",
    "for k in rkeys:\n",
    "    no_rad += data[k] == \"\"\n",
    "    no_rad += data[k] == \"nan\"\n",
    "\n",
    "bad = (data[\"discoverymethod\"] == \"Transit Timing Variations\")*no_mass*no_rad\n",
    "\n",
    "\n",
    "print(\"Removed the following TTV planets missing both mass and radius informatino:\")\n",
    "print(data[\"pl_name\"][bad])\n",
    "\n",
    "for k in data.keys():\n",
    "    data[k] = data[k][~bad]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for targets missing uncertainties on key parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180 stars are missing uncertainties on stellar MASS\n",
      "120 stars are missing uncertainties on stellar RADIUS\n",
      "129 stars are missing uncertainties on stellar TEMPERATURE\n"
     ]
    }
   ],
   "source": [
    "# Check for any stars missing uncertainties on stellar mass or radius\n",
    "bad_mass = (data[\"st_masserr1\"] == \"\") + (data[\"st_masserr2\"] == \"\")\n",
    "nbm = len(np.unique(data[\"hostname\"][bad_mass]))\n",
    "\n",
    "print(\"{0} stars are missing uncertainties on stellar MASS\".format(nbm))\n",
    "\n",
    "\n",
    "# Check for any stars missing uncertainties on stellar mass or radius\n",
    "bad_radius = (data[\"st_raderr1\"] == \"\") + (data[\"st_raderr2\"] == \"\")\n",
    "nbr = len(np.unique(data[\"hostname\"][bad_radius]))\n",
    "\n",
    "print(\"{0} stars are missing uncertainties on stellar RADIUS\".format(nbr))\n",
    "\n",
    "\n",
    "# Check for any stars missing uncertainties on stellar mass or radius\n",
    "bad_temp = (data[\"st_tefferr1\"] == \"\") + (data[\"st_tefferr2\"] == \"\")\n",
    "nbt = len(np.unique(data[\"hostname\"][bad_temp]))\n",
    "\n",
    "print(\"{0} stars are missing uncertainties on stellar TEMPERATURE\".format(nbt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following important RV systems are missing critical data:\n",
      "['GJ 180' 'GJ 3138' 'GJ 3293' 'GJ 433' 'GJ 876' 'HD 125612' 'HD 160691'\n",
      " 'HD 20781' 'HD 27894' 'HD 31527' 'HD 37124' 'HIP 14810' 'Wolf 1061'\n",
      " 'ups And']\n"
     ]
    }
   ],
   "source": [
    "# flag high-multiplicity RV systems which need to be fixed manually\n",
    "npl = np.array(data[\"sy_pnum\"], dtype=\"int\")\n",
    "bad = (bad_mass + bad_radius + bad_temp)*(data[\"system_type\"] == \"Radial Velocity\")*(npl > 2)\n",
    "\n",
    "\n",
    "print(\"The following important RV systems are missing critical data:\")\n",
    "print(np.unique(data[\"hostname\"][bad]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eliminated 246 planets from systems with incomplete stellar data\n"
     ]
    }
   ],
   "source": [
    "# eliminate the low multiplicity and non-RV systems with missing data\n",
    "bad = (bad_mass + bad_radius + bad_temp)*((data[\"system_type\"] != \"Radial Velocity\") + (npl < 3))\n",
    "\n",
    "for k in data.keys():\n",
    "    data[k] = data[k][~bad]\n",
    "\n",
    "print(\"Eliminated {0} planets from systems with incomplete stellar data\".format(np.sum(bad)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fix planet count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, starname in enumerate(np.unique(data[\"hostname\"])):\n",
    "    use = data[\"hostname\"] == starname\n",
    "    \n",
    "    data[\"sy_pnum\"][use] = np.sum(use)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print out the list of high-multiplicity RV systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following 38 RV systems host at least three planets:\n",
      "\n",
      "['47 UMa' '55 Cnc' '61 Vir' 'DMPP-1' 'GJ 1061' 'GJ 163' 'GJ 180' 'GJ 3138'\n",
      " 'GJ 3293' 'GJ 433' 'GJ 581' 'GJ 676 A' 'GJ 876' 'HD 10180' 'HD 125612'\n",
      " 'HD 136352' 'HD 141399' 'HD 158259' 'HD 160691' 'HD 164922' 'HD 181433'\n",
      " 'HD 20781' 'HD 20794' 'HD 215152' 'HD 219134' 'HD 27894' 'HD 31527'\n",
      " 'HD 34445' 'HD 37124' 'HD 40307' 'HD 69830' 'HD 7924' 'HIP 14810'\n",
      " 'HIP 57274' 'Wolf 1061' 'YZ Cet' 'tau Cet' 'ups And']\n"
     ]
    }
   ],
   "source": [
    "npl = np.array(data[\"sy_pnum\"], dtype=\"int\")\n",
    "use = (npl > 2)*(data[\"system_type\"] == \"Radial Velocity\")\n",
    "\n",
    "rv_hostname = np.unique(data[\"hostname\"][use])\n",
    "\n",
    "print(\"The following {0} RV systems host at least three planets:\\n\".format(len(rv_hostname)))\n",
    "print(rv_hostname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "rv_ra = []\n",
    "rv_dec = []\n",
    "\n",
    "for i, rvhn in enumerate(rv_hostname):\n",
    "    use = data[\"hostname\"] == rvhn\n",
    "    \n",
    "    rv_ra.append(data[\"ra\"][use][0])\n",
    "    rv_dec.append(data[\"dec\"][use][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a list of high-multiplicity RV stars to upload to MAST in order to query TICv8\n",
    "# https://mast.stsci.edu/portal/Mashup/Clients/Mast/Portal.html\n",
    "\n",
    "rv_fmt = [\"#@string\", \"ra\", \"dec\"]\n",
    "rv_head = [\"TARGET\", \"RA\", \"DEC\"]\n",
    "rv_data = np.vstack([rv_hostname, rv_ra, rv_dec]).swapaxes(0,1)\n",
    "\n",
    "rv_mast_targets = np.vstack([rv_fmt, rv_head, rv_data])\n",
    "\n",
    "np.savetxt(\"Catalogs/rv_multis_for_mast.csv\", rv_mast_targets, fmt=(\"%s\", \"%s\", \"%s\"), delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check RV stellar property sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here's the data\n",
    "rv_keys, rv_vals = read_csv_file(ps_rv_multi_file, k_index=0, v_index=1)\n",
    "\n",
    "\n",
    "rv_data = {}\n",
    "for k in rv_keys:\n",
    "    rv_data[k] = np.array(get_csv_data(k, rv_keys, rv_vals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "47 UMa\n",
      "-----------\n",
      " Naef et al. 2004 \n",
      " TICv8\n",
      " Wittenmyer et al. 2007 \n",
      " Wittenmyer et al. 2009 \n",
      "\n",
      "55 Cnc\n",
      "-----------\n",
      " Baluev 2015\n",
      " Bourrier et al. 2018\n",
      " Bourrier &amp; H&eacute;brard 2014\n",
      " Butler et al. 1997 \n",
      " Dai et al. 2019\n",
      " Demory et al. 2011\n",
      " Marcy et al. 2002 \n",
      " McArthur et al. 2004 \n",
      " Naef et al. 2004 \n",
      " Salz et al. 2015\n",
      " TICv8\n",
      " Winn et al. 2011 \n",
      "\n",
      "61 Vir\n",
      "-----------\n",
      " Vogt et al. 2010 \n",
      "\n",
      "DMPP-1\n",
      "-----------\n",
      " Staab et al. 2020\n",
      "\n",
      "GJ 1061\n",
      "-----------\n",
      " Dreizler et al. 2020\n",
      "\n",
      "GJ 163\n",
      "-----------\n",
      " Bonfils et al. 2013 \n",
      "\n",
      "GJ 180\n",
      "-----------\n",
      " Feng et al. 2020\n",
      " Tuomi et al. 2014\n",
      "\n",
      "GJ 3138\n",
      "-----------\n",
      " Astudillo-Defru et al. 2017\n",
      "\n",
      "GJ 3293\n",
      "-----------\n",
      " Astudillo-Defru et al. 2015\n",
      " Astudillo-Defru et al. 2017\n",
      "\n",
      "GJ 433\n",
      "-----------\n",
      " Delfosse et al. 2013 \n",
      " Feng et al. 2020\n",
      " Stassun et al. 2017\n",
      " Tuomi et al. 2014\n",
      "\n",
      "GJ 581\n",
      "-----------\n",
      " Bonfils et al. 2005 \n",
      " Mayor et al. 2009 \n",
      " TICv8\n",
      " Vogt et al. 2010\n",
      "\n",
      "GJ 676 A\n",
      "-----------\n",
      " Anglada-Escude & Tuomi 2012 \n",
      " Forveille et al. 2011 \n",
      " Sahlmann et al. 2016\n",
      " Stassun et al. 2017\n",
      "\n",
      "GJ 876\n",
      "-----------\n",
      " Correia et al. 2010 \n",
      " Nelson et al. 2016\n",
      " Rivera et al. 2010 \n",
      " TICv8\n",
      "\n",
      "HD 10180\n",
      "-----------\n",
      " Kane &amp; Gelino 2014\n",
      " Lovis et al. 2011 \n",
      "\n",
      "HD 125612\n",
      "-----------\n",
      " Fischer et al. 2007 \n",
      " Lo Curto et al. 2010 \n",
      " Ment et al. 2018\n",
      " Stassun et al. 2017\n",
      "\n",
      "HD 136352\n",
      "-----------\n",
      " Kane et al. 2020\n",
      " Udry et al. 2019\n",
      "\n",
      "HD 141399\n",
      "-----------\n",
      " H&eacute;brard et al. 2016\n",
      " Vogt et al. 2014\n",
      "\n",
      "HD 158259\n",
      "-----------\n",
      " ExoFOP-TESS TOI\n",
      " Hara et al. 2020\n",
      "\n",
      "HD 160691\n",
      "-----------\n",
      " Butler et al. 2001 \n",
      " Jones et al. 2002 \n",
      " McCarthy et al. 2004 \n",
      " Pepe et al. 2007 \n",
      " Santos et al. 2004 \n",
      " TICv8\n",
      "\n",
      "HD 164922\n",
      "-----------\n",
      " Benatti et al. 2020\n",
      " Butler et al. 2006 \n",
      " Fulton et al. 2016\n",
      " Stassun et al. 2017\n",
      "\n",
      "HD 181433\n",
      "-----------\n",
      " Bouchy et al. 2009 \n",
      " Stassun et al. 2017\n",
      " TICv8\n",
      "\n",
      "HD 20781\n",
      "-----------\n",
      " Udry et al. 2019\n",
      "\n",
      "HD 20794\n",
      "-----------\n",
      " Feng et al. 2017\n",
      " Pepe et al. 2011 \n",
      "\n",
      "HD 215152\n",
      "-----------\n",
      " Delisle et al. 2018\n",
      "\n",
      "HD 219134\n",
      "-----------\n",
      " Gillon et al. 2017\n",
      " Johnson et al. 2016\n",
      " Motalebi et al. 2015\n",
      " Vogt et al. 2015\n",
      "\n",
      "HD 27894\n",
      "-----------\n",
      " K&uuml;rster et al. 2015\n",
      " Moutou et al. 2005 \n",
      " Trifonov et al. 2017\n",
      "\n",
      "HD 31527\n",
      "-----------\n",
      " Udry et al. 2019\n",
      "\n",
      "HD 34445\n",
      "-----------\n",
      " Howard et al. 2010 \n",
      " Stassun et al. 2017\n",
      " Vogt et al. 2017\n",
      "\n",
      "HD 37124\n",
      "-----------\n",
      " Butler et al. 2003 \n",
      " Gozdziewski et al. 2006\n",
      " Vogt et al. 2005 \n",
      " Wright et al. 2011\n",
      "\n",
      "HD 40307\n",
      "-----------\n",
      " D&iacute;az et al. 2016\n",
      " TICv8\n",
      " Tuomi et al. 2013 \n",
      "\n",
      "HD 69830\n",
      "-----------\n",
      " Lovis et al. 2006 \n",
      "\n",
      "HD 7924\n",
      "-----------\n",
      " Fulton et al. 2015\n",
      " Howard et al. 2009 \n",
      " Stassun et al. 2017\n",
      " TICv8\n",
      "\n",
      "HIP 14810\n",
      "-----------\n",
      " Butler et al. 2006 \n",
      " Ment et al. 2018\n",
      " Stassun et al. 2017\n",
      " TICv8\n",
      " Wright et al. 2009 \n",
      "\n",
      "HIP 57274\n",
      "-----------\n",
      " Fischer et al. 2012 \n",
      " Stassun et al. 2017\n",
      " TICv8\n",
      "\n",
      "Wolf 1061\n",
      "-----------\n",
      " Astudillo-Defru et al. 2017\n",
      " Wright et al. 2016\n",
      "\n",
      "YZ Cet\n",
      "-----------\n",
      " Astudillo-Defru et al. 2017\n",
      " Robertson 2018\n",
      "\n",
      "tau Cet\n",
      "-----------\n",
      " Feng et al. 2017\n",
      "\n",
      "ups And\n",
      "-----------\n",
      " Butler et al. 1997 \n",
      " Curiel et al. 2011 \n",
      " Naef et al. 2004 \n",
      " TICv8\n",
      " Wittenmyer et al. 2007 \n"
     ]
    }
   ],
   "source": [
    "for i, star in enumerate(np.unique(rv_hostname)):\n",
    "    use = rv_data[\"hostname\"] == star\n",
    "    \n",
    "    refs = np.unique(rv_data[\"st_refname\"][use])\n",
    "    \n",
    "    print(\"\")\n",
    "    print(star)\n",
    "    print(\"-----------\")\n",
    "    for r in refs:\n",
    "        \n",
    "        \n",
    "        loc = r.find(\"target=ref>\")\n",
    "        ref = r[loc+11:-4]\n",
    "        \n",
    "        if ref[0] == \" \":\n",
    "            ref = ref[1:]\n",
    "        \n",
    "        print(\"\", ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write out catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing complete!\n"
     ]
    }
   ],
   "source": [
    "WRITENEW = True\n",
    "if WRITENEW:\n",
    "    filepath = MAINPATH + 'Catalogs/oviraptor_A_cleaned_and_crossmatched.csv'\n",
    "\n",
    "    with open(filepath, \"w\") as outfile:\n",
    "        writer = csv.writer(outfile)\n",
    "        writer.writerow(data.keys())\n",
    "        writer.writerows(zip(*data.values()))\n",
    "\n",
    "print(\"Writing complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
