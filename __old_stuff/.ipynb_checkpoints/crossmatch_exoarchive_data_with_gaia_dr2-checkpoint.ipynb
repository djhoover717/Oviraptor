{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fills in missing values in the exoarchive catalog using more recently-measured values from the Gaia DR2.\n",
    "### Removes planets that are controversial or have detection methods other than transit, RV, or TTV.\n",
    "### Outputs the new results in ovriraptor_crossmatch_catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT STATEMENTS AND PRELIMINARIES\n",
    "\n",
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "from astropy.constants import R_earth\n",
    "from astropy.constants import R_jup\n",
    "\n",
    "RERJ = float(R_earth/R_jup)\n",
    "\n",
    "\n",
    "pi = np.pi\n",
    "\n",
    "MAINPATH = '/Users/research/projects/oviraptor/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in exoarchive data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file names\n",
    "planet_file = MAINPATH + \"catalogues/exoarchive_systems_20201204.csv\"\n",
    "\n",
    "# convenience function to read in csv file\n",
    "def read_csv_file(filename):\n",
    "    data = []\n",
    "    with open(filename) as infile:\n",
    "        reader = csv.reader(infile)\n",
    "\n",
    "        for row in reader:\n",
    "            data.append(row)\n",
    "\n",
    "        keys   = data[107]\n",
    "        values = data[108:]\n",
    "            \n",
    "        return keys, values\n",
    "\n",
    "\n",
    "# READ IN DR25 DATABASE -- https://exoplanetarchive.ipac.caltech.edu\n",
    "csv_keys, csv_data = read_csv_file(planet_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convenience functions to pull data from csv files\n",
    "def getdata(keyname,keys=csv_keys,data=csv_data):\n",
    "    '''\n",
    "    keyname = (string) of column definition, see CKS documentation\n",
    "    '''\n",
    "    kid = keys.index(keyname)\n",
    "    \n",
    "    outdata = []\n",
    "    for row in data:\n",
    "        outdata.append(row[kid])\n",
    "    \n",
    "    return outdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data into a dictionary\n",
    "data = {}\n",
    "for k in csv_keys:\n",
    "    data[k] = getdata(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of queried objects = 4307\n"
     ]
    }
   ],
   "source": [
    "def check_lengths(data):\n",
    "    keys = data.keys()\n",
    "    k0   = list(keys)[0]\n",
    "    L0   = len(data[k0])\n",
    "    \n",
    "    for k in keys:\n",
    "        if len(data[k]) != L0:\n",
    "            raise ValueError('inconsistent array lengths')\n",
    "            \n",
    "    return None\n",
    "\n",
    "\n",
    "def convert_to_arrays(data):\n",
    "    keys = data.keys()\n",
    "    dnew = {}\n",
    "    \n",
    "    for k in keys:\n",
    "        dnew[k] = np.asarray(data[k])\n",
    "        \n",
    "    return dnew       \n",
    "\n",
    "\n",
    "\n",
    "# grab a reference key\n",
    "k0 = list(data.keys())[0]\n",
    "\n",
    "\n",
    "# convert to arrays\n",
    "data = convert_to_arrays(data)\n",
    "\n",
    "\n",
    "# only use default (single reference) values\n",
    "keep = data['default_flag']  == '1'\n",
    "\n",
    "for k in data.keys():\n",
    "    data[k] = data[k][keep]\n",
    "\n",
    "\n",
    "print('total number of queried objects =', len(data[k0]))\n",
    "\n",
    "\n",
    "check_lengths(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove unwanted objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed 190 objects due to non-relevant DETECTION METHOD\n",
      "removed 10 objects flagged as CONTROVERSIAL\n",
      "\n",
      "after cuts, 4107 objects remain\n",
      "\n",
      "3273 TRANSITING planets\n",
      "813 RADIAL VELOCITY planets\n",
      "21 TTV planets\n"
     ]
    }
   ],
   "source": [
    "# filter detection methods\n",
    "keep = (data[\"discoverymethod\"] == \"Transit\") + (data[\"discoverymethod\"] == \"Radial Velocity\") + \\\n",
    "       (data[\"discoverymethod\"] == \"Transit Timing Variations\")\n",
    "\n",
    "for k in data.keys():\n",
    "    data[k] = data[k][keep]\n",
    "\n",
    "print(\"removed {0} objects due to non-relevant DETECTION METHOD\".format(np.sum(~keep)))\n",
    "\n",
    "\n",
    "# controversial flag\n",
    "bad = data[\"pl_controv_flag\"] == \"1\"\n",
    "\n",
    "for k in data.keys():\n",
    "    data[k] = data[k][~bad]\n",
    "\n",
    "print(\"removed {0} objects flagged as CONTROVERSIAL\".format(np.sum(bad)))\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nafter cuts, {0} objects remain\\n\".format(len(data[k0])))\n",
    "\n",
    "print(\"{0} TRANSITING planets\".format(np.sum(data[\"discoverymethod\"] == \"Transit\")))\n",
    "print(\"{0} RADIAL VELOCITY planets\".format(np.sum(data[\"discoverymethod\"] == \"Radial Velocity\")))\n",
    "print(\"{0} TTV planets\".format(np.sum(data[\"discoverymethod\"] == \"Transit Timing Variations\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check stellar parameter consistency for each system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "npl = np.array(data[\"sy_pnum\"], dtype=\"int\")\n",
    "\n",
    "starname = np.array(data[\"hostname\"])\n",
    "detmet = np.array(data[\"discoverymethod\"])\n",
    "\n",
    "Mstar = np.array(data[\"st_mass\"])\n",
    "Mstar_err1 = np.array(data[\"st_masserr1\"])\n",
    "Mstar_err2 = np.array(data[\"st_masserr2\"])\n",
    "\n",
    "Rstar = np.array(data[\"st_rad\"])\n",
    "Rstar_err1 = np.array(data[\"st_raderr1\"])\n",
    "Rstar_err2 = np.array(data[\"st_raderr2\"])\n",
    "\n",
    "uniquesys = np.unique(starname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# some planets have no stellar mass/radius given; others have a value for only a single planet in a system\n",
    "# for multis where one planet has a stellar mass/radius value, broadcast this to all planets in the system\n",
    "for i, s in enumerate(uniquesys):\n",
    "    use = starname == s\n",
    "    \n",
    "    # first fix stellar masses\n",
    "    if np.any(Mstar[use] == \"\"):\n",
    "        unique_ms = np.unique(Mstar[use])\n",
    "        unique_ms_err1 = np.unique(Mstar_err1[use])\n",
    "        unique_ms_err2 = np.unique(Mstar_err2[use])\n",
    "        \n",
    "        if len(unique_ms) == 2:\n",
    "            Mstar[use] = str(unique_ms[unique_ms != ''].item())\n",
    "            \n",
    "            try:\n",
    "                Mstar_err1[use] = str(unique_ms_err1[unique_ms_err1 != ''].item())\n",
    "                Mstar_err2[use] = str(unique_ms_err2[unique_ms_err2 != ''].item())\n",
    "            except:\n",
    "                Mstar_err1[use] = ''\n",
    "                Mstar_err2[use] = ''\n",
    "    \n",
    "    # then fix stellar radii\n",
    "    if np.any(Rstar[use] == \"\"):\n",
    "        unique_rs = np.unique(Rstar[use])\n",
    "        unique_rs_err1 = np.unique(Rstar_err1[use])\n",
    "        unique_rs_err2 = np.unique(Rstar_err2[use])\n",
    "        \n",
    "\n",
    "        if len(unique_rs) == 2:\n",
    "            Rstar[use] = str(unique_rs[unique_rs != ''].item())\n",
    "            try:\n",
    "                Rstar_err1[use] = str(unique_rs_err1[unique_rs_err1 != ''].item())\n",
    "                Rstar_err2[use] = str(unique_rs_err2[unique_rs_err2 != ''].item())\n",
    "            except:\n",
    "                Rstar_err1[use] = ''\n",
    "                Rstar_err2[use] = ''\n",
    "            \n",
    "\n",
    "data[\"st_mass\"] = np.copy(Mstar)\n",
    "data[\"st_masserr1\"] = np.copy(Mstar_err1)\n",
    "data[\"st_masserr2\"] = np.copy(Mstar_err2)\n",
    "\n",
    "data[\"st_rad\"] = np.copy(Rstar)\n",
    "data[\"st_raderr1\"] = np.copy(Rstar_err1)\n",
    "data[\"st_raderr2\"] = np.copy(Rstar_err2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Missing MASS\n",
      "['GJ 163']\n",
      "\n",
      "\n",
      "Missing RADIUS\n",
      "['GJ 163' 'GJ 180' 'GJ 433' 'GJ 667 C' 'HD 133131 A' 'HD 133131 B'\n",
      " 'HD 136352' 'HD 141399' 'HD 160691' 'HD 20781' 'HD 20794' 'HD 27894'\n",
      " 'HD 31527' 'HD 37124' 'HD 40307' 'HD 69830' 'tau Cet']\n"
     ]
    }
   ],
   "source": [
    "RV = data[\"discoverymethod\"] == \"Radial Velocity\"\n",
    "\n",
    "npl = np.array(data['sy_pnum'][RV], dtype=\"int\")\n",
    "Mstar = np.array(data['st_mass'][RV])\n",
    "Rstar = np.array(data['st_rad'][RV])\n",
    "starname = np.array(data['hostname'][RV])\n",
    "planetname = np.array(data['pl_name'][RV])\n",
    "\n",
    "print(\"\\n\\nMissing MASS\")\n",
    "print(np.unique(starname[(Mstar == '')*(npl > 2)]))\n",
    "\n",
    "print(\"\\n\\nMissing RADIUS\")\n",
    "print(np.unique(starname[(Rstar == '')*(npl > 2)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in Kepler names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "kepnamepath = MAINPATH + \"catalogues/kepler_names.txt\"\n",
    "\n",
    "# read in the stellar output parameters\n",
    "with open(kepnamepath, \"r\") as infile:\n",
    "    raw_kepnames = []\n",
    "    \n",
    "    for i, line in enumerate(infile):\n",
    "        raw_kepnames.append(line.split(\",\"))\n",
    "            \n",
    "raw_kepnames = np.array(raw_kepnames)\n",
    "\n",
    "# strip off trailing \\newline commands\n",
    "for i in range(len(raw_kepnames)):\n",
    "    raw_kepnames[i,-1] = raw_kepnames[i,-1].strip(\"\\n\").strip(\"\\ \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "kepnames = {}\n",
    "\n",
    "for i, k in enumerate(raw_kepnames[0]):\n",
    "    kepnames[k] = raw_kepnames[1:,i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in Gaia DR2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaiapath = MAINPATH + \"catalogues/berger_2020_gaia_kepler_tab2_output.txt\"\n",
    "\n",
    "# read in the stellar output parameters\n",
    "with open(gaiapath, \"r\") as infile:\n",
    "    raw_gaia_data = []\n",
    "    \n",
    "    for i, line in enumerate(infile):\n",
    "        raw_gaia_data.append(line.split(\"&\"))\n",
    "            \n",
    "raw_gaia_data = np.array(raw_gaia_data)\n",
    "\n",
    "\n",
    "# strip off trailing \\newline commands\n",
    "for i in range(len(raw_gaia_data)):\n",
    "    raw_gaia_data[i,-1] = raw_gaia_data[i,-1].strip(\"\\n\").strip(\"\\ \")\n",
    "    \n",
    "    \n",
    "gaia_stars = {}\n",
    "\n",
    "for i, k in enumerate(raw_gaia_data[0]):\n",
    "    gaia_stars[k] = raw_gaia_data[1:,i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaiapath = MAINPATH + \"catalogues/berger_2020_gaia_kepler_planets.txt\"\n",
    "\n",
    "gaia_planets = {}\n",
    "\n",
    "gaia_planets[\"KIC\"] = np.loadtxt(gaiapath, skiprows=32, dtype=\"str\", usecols=0)\n",
    "gaia_planets[\"radius\"] = np.loadtxt(gaiapath, skiprows=32, dtype=\"str\", usecols=3)\n",
    "gaia_planets[\"radius_err1\"] = np.loadtxt(gaiapath, skiprows=32, dtype=\"str\", usecols=4)\n",
    "gaia_planets[\"radius_err2\"] = np.loadtxt(gaiapath, skiprows=32, dtype=\"str\", usecols=5)\n",
    "gaia_planets[\"sma\"] = np.loadtxt(gaiapath, skiprows=32, dtype=\"str\", usecols=6)\n",
    "gaia_planets[\"sma_err1\"] = np.loadtxt(gaiapath, skiprows=32, dtype=\"str\", usecols=7)\n",
    "gaia_planets[\"sma_err2\"] = np.loadtxt(gaiapath, skiprows=32, dtype=\"str\", usecols=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-match Kepler vs. Gaia and combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaia_kic = np.asarray(gaia_stars[\"KIC\"], dtype=\"int\")\n",
    "\n",
    "for i in range(len(data[k0])):\n",
    "    hostname = data[\"hostname\"][i]\n",
    "    \n",
    "    if hostname[:3] == \"Kep\":\n",
    "        \n",
    "        for j, kname in enumerate(kepnames[\"kepler_name\"]):\n",
    "            if kname[:-2] == hostname:\n",
    "                kic = int(kepnames[\"kepid\"][j])\n",
    "        \n",
    "        match = gaia_kic == kic\n",
    "        \n",
    "        if np.sum(match) == 1:\n",
    "            data[\"st_refname\"][i] = \"Berger et al. 2020\"\n",
    "            \n",
    "            data[\"st_teff\"][i] = gaia_stars[\"iso_teff\"][match][0]\n",
    "            data[\"st_tefferr1\"][i] = gaia_stars[\"iso_teff_err1\"][match][0]\n",
    "            data[\"st_tefferr1\"][i] = gaia_stars[\"iso_teff_err2\"][match][0]\n",
    "            data[\"st_tefflim\"][i]  = \"0\"\n",
    "            \n",
    "            data[\"st_rad\"][i] = gaia_stars[\"iso_rad\"][match][0]\n",
    "            data[\"st_raderr1\"][i] = gaia_stars[\"iso_rad_err1\"][match][0]\n",
    "            data[\"st_raderr1\"][i] = gaia_stars[\"iso_rad_err2\"][match][0]\n",
    "            data[\"st_radlim\"][i]  = \"0\"\n",
    "            \n",
    "            data[\"st_mass\"][i] = gaia_stars[\"iso_mass\"][match][0]\n",
    "            data[\"st_masserr1\"][i] = gaia_stars[\"iso_mass_err1\"][match][0]\n",
    "            data[\"st_masserr1\"][i] = gaia_stars[\"iso_mass_err2\"][match][0]\n",
    "            data[\"st_masslim\"][i]  = \"0\"\n",
    "            \n",
    "            data[\"st_met\"][i] = gaia_stars[\"iso_feh\"][match][0]\n",
    "            data[\"st_meterr1\"][i] = gaia_stars[\"iso_feh_err1\"][match][0]\n",
    "            data[\"st_meterr1\"][i] = gaia_stars[\"iso_feh_err2\"][match][0]\n",
    "            data[\"st_metlim\"][i]  = \"0\"\n",
    "            data[\"st_metratio\"][i]  = \"[Fe/H]\"\n",
    "            \n",
    "            data[\"st_logg\"][i] = gaia_stars[\"iso_logg\"][match][0]\n",
    "            data[\"st_loggerr1\"][i] = gaia_stars[\"iso_logg_err1\"][match][0]\n",
    "            data[\"st_loggerr1\"][i] = gaia_stars[\"iso_logg_err2\"][match][0]\n",
    "            data[\"st_logglim\"][i]  = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaia_kic = np.asarray(gaia_planets[\"KIC\"], dtype=\"int\")\n",
    "\n",
    "count = 0\n",
    "\n",
    "for i in range(len(data[k0])):\n",
    "    hostname = data[\"hostname\"][i]\n",
    "    \n",
    "    if hostname[:3] == \"Kep\":\n",
    "        \n",
    "        for j, kname in enumerate(kepnames[\"kepler_name\"]):\n",
    "            if kname[:-2] == hostname:\n",
    "                kic = int(kepnames[\"kepid\"][j])\n",
    "        \n",
    "        match = gaia_kic == kic\n",
    "        \n",
    "        if np.sum(match) == 1:\n",
    "            data[\"pl_rade\"][i] = gaia_planets[\"radius\"][match][0]\n",
    "            data[\"pl_radeerr1\"][i] = gaia_planets[\"radius_err1\"][match][0]\n",
    "            data[\"pl_radeerr1\"][i] = gaia_planets[\"radius_err2\"][match][0]\n",
    "            data[\"pl_radelim\"][i]  = \"0\"\n",
    "            \n",
    "            data[\"pl_radj\"][i] = str(np.round(float(gaia_planets[\"radius\"][match][0])*RERJ,3))\n",
    "            data[\"pl_radjerr1\"][i] = str(np.round(float(gaia_planets[\"radius_err1\"][match][0])*RERJ,3))\n",
    "            data[\"pl_radjerr1\"][i] = str(np.round(float(gaia_planets[\"radius_err2\"][match][0])*RERJ,3))\n",
    "            data[\"pl_radjlim\"][i]  = \"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write out catalogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "WRITENEW = True\n",
    "if WRITENEW:\n",
    "    filepath = MAINPATH + 'catalogues/oviraptor_crossmatch_catalog.csv'\n",
    "\n",
    "    with open(filepath, \"w\") as outfile:\n",
    "        writer = csv.writer(outfile)\n",
    "        writer.writerow(data.keys())\n",
    "        writer.writerows(zip(*data.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
